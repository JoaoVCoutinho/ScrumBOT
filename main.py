import json
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate

# ----------------------
# Configura√ß√£o do prompt
# ----------------------
template = """
Voc√™ √© um Scrum Master virtual chamado ScrumBOT AI. 
Seu papel √© ajudar equipes a aplicar m√©todos √°geis. 
Siga estas diretrizes:

- Transformar descri√ß√µes de funcionalidades em User Stories no formato:
  "Como [persona], quero [funcionalidade], para [benef√≠cio]".
- Sempre sugerir crit√©rios de aceita√ß√£o.
- Manter o tom de um Scrum Master ajudando o time.
- Auxiliar em prioriza√ß√£o, estimativas, detec√ß√£o de impedimentos, retrospectiva e gera√ß√£o de Kanban.
- Responda sempre em portugu√™s do Brasil.

Hist√≥rico da conversa: {context}

Pergunta do usu√°rio: {question}

Resposta:
"""

model = OllamaLLM(model="llama3")
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# ----------------------
# Backlog
# ----------------------
backlog = []

def salvar_backlog():
    with open("backlog.json", "w", encoding="utf-8") as f:
        json.dump(backlog, f, ensure_ascii=False, indent=4)

def carregar_backlog():
    global backlog
    try:
        with open("backlog.json", "r", encoding="utf-8") as f:
            backlog = json.load(f)
    except FileNotFoundError:
        backlog = []

# ----------------------
# Fun√ß√µes especiais
# ----------------------
def priorizar_backlog(metodo="MoSCoW"):
    if not backlog:
        print("‚ö†Ô∏è Nenhuma User Story no backlog ainda.")
        return
    backlog_texto = "\n".join([f"- {item}" for item in backlog])
    prompt_priorizacao = f"""
Voc√™ √© um Scrum Master. Organize o seguinte backlog aplicando a t√©cnica {metodo}.

Backlog:
{backlog_texto}

Explique rapidamente como foi feita a prioriza√ß√£o.
"""
    result = model.invoke(prompt_priorizacao)
    print("\nüìä Backlog Prioritizado:\n")
    print(result)

def estimar_backlog():
    if not backlog:
        print("‚ö†Ô∏è Nenhuma User Story no backlog ainda.")
        return
    backlog_texto = "\n".join([f"- {item}" for item in backlog])
    prompt_estimativa = f"""
Voc√™ √© um facilitador de Sprint Planning. 
Sugira estimativas de pontos de hist√≥ria (1,2,3,5,8,13,21) para as seguintes User Stories. Justifique brevemente cada estimativa.

Backlog:
{backlog_texto}

Formato:
- User Story
  Estimativa: X pontos
  Justificativa: ...
  Responda sempre em portugu√™s do Brasil.
"""
    result = model.invoke(prompt_estimativa)
    print("\nüéØ Estimativas sugeridas:\n")
    print(result)

def detectar_impedimentos():
    print("\nDigite os registros do Daily Stand-up (ou 'fim' para encerrar):")
    registros = []
    while True:
        linha = input("Registro: ")
        if linha.lower() == "fim":
            break
        registros.append(linha)
    if not registros:
        print("‚ö†Ô∏è Nenhum registro fornecido.")
        return
    registros_texto = "\n".join([f"- {r}" for r in registros])
    prompt_impedimentos = f"""
Voc√™ √© um Scrum Master virtual. Analise os seguintes registros de Daily Stand-up 
e identifique impedimentos ou problemas recorrentes (depend√™ncias, gargalos, sobrecarga).

Registros:
{registros_texto}
"""
    result = model.invoke(prompt_impedimentos)
    print("\nüö® Impedimentos detectados:\n")
    print(result)

def retrospecitiva_agil():
    print("\nDigite os feedbacks da Sprint (ou 'fim' para encerrar):")
    feedbacks = []
    while True:
        linha = input("Feedback: ")
        if linha.lower() == "fim":
            break
        feedbacks.append(linha)
    if not feedbacks:
        print("‚ö†Ô∏è Nenhum feedback fornecido.")
        return
    feedbacks_texto = "\n".join([f"- {f}" for f in feedbacks])
    prompt_retro = f"""
Voc√™ √© um Scrum Master virtual. Organize os feedbacks em Start, Stop, Continue
e sugira planos de a√ß√£o pr√°ticos para cada categoria.

Feedbacks:
{feedbacks_texto}
"""
    result = model.invoke(prompt_retro)
    print("\nüìã Retrospectiva √Ågil:\n")
    print(result)

def cliente_virtual():
    print("\nInteragindo com o Cliente Virtual (Product Owner). Digite 'fim' para encerrar.\n")
    contexto = "Voc√™ √© o Product Owner do projeto, respons√°vel por esclarecer d√∫vidas, negociar requisitos e validar entregas com o time."
    while True:
        pergunta = input("Time: ")
        if pergunta.lower() == "fim":
            print("Encerrando intera√ß√£o com o Cliente Virtual ‚úÖ\n")
            break
        prompt_cliente = f"""
{contexto}

O time perguntou: {pergunta}

Responda como um Product Owner profissional.
"""
        resposta = model.invoke(prompt_cliente)
        print("Cliente Virtual:", resposta)

def gerar_kanban():
    if not backlog:
        print("‚ö†Ô∏è Nenhuma User Story no backlog ainda.")
        return
    backlog_texto = "\n".join([f"- {item}" for item in backlog])
    prompt_kanban = f"""
Voc√™ √© um Scrum Master virtual. 
Organize o backlog em um quadro Kanban com colunas: To Do, Doing, Done.
Backlog:
{backlog_texto}

Responda no formato:
To Do:
- ...
Doing:
- ...
Done:
- ...
"""
    result = model.invoke(prompt_kanban)
    print("\nüìã Quadro Kanban sugerido pela IA:\n")
    print(result)

# ----------------------
# Loop principal
# ----------------------
def handle_conversation():
    carregar_backlog()
    context = ""
    print(
            "Bem-vindo ao *ScrumBOT AI*!\n"
            "Este √© o seu assistente para M√©todos √Ågeis.\n"
            "Eu posso ajudar voc√™ e sua equipe a:\n"
            "‚úÖ Criar User Stories a partir das suas ideias\n"
            "‚úÖ Priorizar o backlog automaticamente (MoSCoW, WSJF...)\n"
            "‚úÖ Sugerir estimativas de esfor√ßo (Planning Poker virtual)\n"
            "‚úÖ Detectar impedimentos nas Dailies\n"
            "‚úÖ Conduzir retrospectivas √°geis com insights\n"
            "‚úÖ Simular o papel de um Product Owner (cliente)\n"
            "‚úÖ Gerar um quadro Kanban automaticamente\n\n"
            "Dica: comece me dizendo uma funcionalidade que gostaria de implementar no sistema\n"
            "Ou digite 'ajuda' para verificar comandos especiais (IMPORTANTE!)"
        )
      
    while True:
        user_input = input("Voc√™: ").strip().lower()
        if user_input == 'exit':
            print("Encerrando... backlog salvo em backlog.json ‚úÖ")
            salvar_backlog()
            break
        elif user_input == 'priorizar':
            priorizar_backlog("MoSCoW")
            continue
        elif user_input == 'estimar':
            estimar_backlog()
            continue
        elif user_input == 'impedimentos':
            detectar_impedimentos()
            continue
        elif user_input == 'retrospectiva':
            retrospecitiva_agil()
            continue
        elif user_input == 'cliente':
            cliente_virtual()
            continue
        elif user_input == 'kanban':
            gerar_kanban()
            continue
        elif user_input == 'ajuda':
            print(
            "Comandos dispon√≠veis:\n"
            "- exit ‚Üí sair\n"
            "- priorizar ‚Üí prioriza√ß√£o do backlog\n"
            "- estimar ‚Üí Sprint Planning\n"
            "- impedimentos ‚Üí detectar problemas\n"
            "- retrospectiva ‚Üí Retrospectiva √Ågil\n"
            "- cliente ‚Üí simular Product Owner\n"
            "- kanban ‚Üí gerar quadro Kanban\n"
            )
            continue


        # Conversa normal para gerar User Stories
        result = chain.invoke({"context": context, "question": user_input})
        print("ScrumBOT:", result)

        context += f"\nUser: {user_input}\nAI: {result}" 

        # Captura User Story
        if "Como " in result:
            backlog.append(result.strip())
            salvar_backlog()
            print("üìå User Story adicionada ao backlog!")


# ----------------------
# Executar
# ----------------------
if __name__ == "__main__":
    handle_conversation()
